%!TEX root=../document.tex

\section{Ergebnisse}
\label{sec:Ergebnisse}

\subsection{Installation und Testdurchlauf von Ori}
\label{subsec:Installation und Testdurchlauf von Ori}
Für die Übungsdurchführung wird mithife von Vagrant eine 'ubuntu/wily64'-Box bereitgestellt. Das dazugehörige Vagrantfile befindet sich in unserem Repository. \cite{repo} Zum Ausprobieren wurde dazu noch eine Debian-VM mit LXDE aufgesetzt, um die Funktionalität optimal testen zu können. Auf der Herstellerseite sind auch einige der wichtigsten Kernaspekte von OriFS aufgelistet: 

\begin{itemize}
	\item Peer-to-Peer \newline
	'Ori operates peer-to-peer among your devices and uses existing secure communication channels such as SSH to transfer your data.'
	\item Work Offline \newline
	'In today's world we often are moving around with intermittent network connectivity and we want to access our data when we board a plane or travel to the office.'
	\item Secure \newline
	'Ori can verify the authenticity of your data and ensure it has not been tampered with. Data is transfered over SSH. Device discovery and automatic synchronization uses a shared secret to initiate transfers.'
	\item Instant Access \newline
	'Instantly mount remote file systems and start working while you synchronize data in the background.' \cite{OrifsStanford}
\end{itemize}

\subsubsection{Fehler bei Installation über Ubuntu PPA}
\label{subsubsec:Fehler bei Installation über Ubuntu PPA}
Die Installationsanleitung auf der Seite der Hersteller \cite{OrifsStanford} ist falsch. \newline
\begin{lstlisting}[frame=single, language=bash, caption=Anleitung zur Installation laut Hersteller - fehlerhaft]
add-apt-repository ppa:ezyang/ppa
apt-get update
# Hier entsteht der Fehler: 404 Not Found
# Einige Indexdateien konnten nicht heruntergeladen werden. 
# Sie wurden ignoriert oder alte an ihrer Stelle benutzt.
apt-get install ori # Funktioniert nicht!
\end{lstlisting}
Hierbei kommt es zu einem 404-Fehler, die Informationen zur Installation sind nicht mehr aktuell. Diese Paketquelle ist nicht mehr vorhanden, da sie bereits in den Standard-Paketquellen vorhanden sind.

\clearpage

\subsubsection{Installation in Ubuntu}
\label{subsubsec:Installation in Ubuntu}
Im Zuge dessen ist es regelrecht einfach, OriFS zu installieren. Folgende Befehle sind notwendig:
\begin{lstlisting}[frame=single, language=bash, caption=Anleitung zur Installation]c
apt-get update
apt-get install ori
\end{lstlisting}
Daraufhin ist OriFS unter Ubuntu vollständig installiert.

\subsubsection{Kompilieren und Installation 'from source' mit SCons}
\label{subsubsec:Kompilieren und Installation 'from source' mit SCons}
OriFS ist laut den Herstellern verfügbar für FreeBSD, OS X, Arch Linux und Ubuntu.
Es gibt aber natürlich auch eine andere Art, das Programm zu erlangen: Direkt über den frei zugänglichen Quelltext kompilieren und installieren. Dafür sind folgende Schritte notwendig:
\begin{lstlisting}[frame=single, caption=Anleitung zur Installation 'from source']
apt-get update

apt-get install scons build-essential pkg-config -y
apt-get install libboost-dev uuid-dev libfuse-dev libevent-dev libssl-dev -y

wget https://bitbucket.org/orifs/ori/downloads/ori-0.8.1.tar.xz
tar xvfJ ori-0.8.1.tar.xz
cd ori-0.8.1

scons

scons PREFIX=/usr/local/ install
\end{lstlisting}
Hierbei wird unter anderem SCons als Build-Tool verwendet. Der Installationspfad '/usr/local' ist daher vorzuziehen, weil hier vom Administrator Programme und Dateien ablegt werden können, die von der entsprechenden Distribution des jeweiligen Systems unabhängig installiert worden sind, wie etwa selbstkompilierte oder unabhängig von der Distribution heruntergeladene Programme. 

\subsubsection{OriFS-Testfälle ausführen}
\label{subsubsec:OriFS-Testfälle ausführen}
Im entpackten Sourcecode-Archiv sind auch die von uns gewünschten Testfälle enthalten. Folgendes Skript führt diese aus:
\begin{lstlisting}[frame=single, language=bash, caption=Erster Versuch Testfälle]
./runtests.sh
\end{lstlisting}
Nach nur wenigen Testfällen schlägt der Lauf fehl. Eine Recherche ergibt, dass dies keineswegs ein Einzelfall ist. Das mitgelieferte README-File, zitiert: \newline
\textit{'There are multiple unit tests available inside the build directory.  The
end-to-end tests are in ongoing development and only about half of them are
expected to run reliably.  In a future release the tests will be improved to
make it easier to run.'} \newline
\clearpage
Die in der Aufgabenstellung beschriebene Hilfestellung schafft Abhilfe. \cite{OrifsBitbucket} Im folgenden Schritt wird im extrahierten Archiv die Datei \textit{runtests\_config.sh} angelegt. Das File beinhaltet folgende Zeilen:
\begin{lstlisting}[frame=single, language=bash, caption=Inhalt runtests\_config.sh]
# Required for Mac OS X and FreeBSD only (comment out on Linux machines)
# export UMOUNT="umount"

# Not updated to new CLI

HTTP_CLONE="no"

HTTP_PULL="no"

MERGE="no"

MOUNT_WRITE="no"

MOUNT_WRITE_PYTHON_MT="no"
\end{lstlisting}
Die Unit-Tests, die nicht funktionieren, werden übersprungen. Bei Fehlern muss der Ordner \textit{tempdir} sowie die Testrepositories in dem im Home-Verzeichnis versteckten Ordner \textit{~/.ori/<name>.ori} gelöscht werden. Ein SSH-Public Key muss ebenso angelegt werden, um ein passwortloses Anmelden zu ermöglichen. Die Tests mit der Numer 54 und 61 resultieren in einem Syntaxfehler. Das Package ist nicht auf dem Rechner vorhanden, liegt daher nicht an OriFS. Nach ausgedehntem Troubleshooting und Lesen der Fehlermeldung konnte auch dieser Fehler behoben werden. Die Files im Ordner \textit{ori\_tests}, \textit{53-mount-write-wget.sh} sowie \textit{61-mount-write-wget-mt.sh}, müssen ausgebessert werden. Die jeweils erste Zeile muss auf die aktuell installierte Version von \textit{wget} zeigen. In diesem Fall wurde der String auf \textit{wget-1.16.1} ausgebessert. Erst jetzt funktionieren die Tests ohne Probleme. Die Testfälle 01-05, 11-15, 30, 52-53, 60-61 wurden erfolgreich ausgeführt, 21-22, 35, 51, 62 wurden übersprungen.

\subsection{Einsatz / Dokumentation der Ori API}
\label{subsec:Einsatz / Dokumentation der Ori API}
Jeder der angeschriebenen Befehle wurde ausgeführt und dokumentiert. Jeglicher Ausgangspunkt in der Konsole ist das Verzeichnis \textit{/home/mweinberger}.

\subsubsection{newfs - Anlegen eines Filesystems}
\label{subsubsec:newfs - Anlegen eines Filesystems}
Das Erstellen eines Dateisystems ist wie anzunehmen der erste Schritt bei OriFS. Mithilfe des Befehls \textit{ori} wird somit eines erstellt, und im Anschluss mit einem leeren, neu erstellten Verzeichnis eingehängt.
\begin{lstlisting}[frame=single, caption=newfs]
ori newfs dezsys

mkdir dezsys

orifs /home/mweinberger/dezsys
\end{lstlisting}

\subsubsection{removefs - Löschen eines Filesystems}
\label{subsubsec:removefs - Löschen eines Filesystems}
Natürlich lässt sich das Dateisystem auch wieder löschen, ebenso mit dem \textit{ori}-Befehl, es muss lediglich ausgehängt sein. Das vorher erstellte Verzeichnis kann auch gelöscht werden, sofern es nicht mehr benötigt wird.
\begin{lstlisting}[frame=single, caption=removefs]
umount /home/mweinberger/dezsys

ori removefs dezsys

rm -rf dezsys
\end{lstlisting}

\subsubsection{list - Lokale Dateisysteme auflisten}
\label{subsubsec:list - Lokale Dateisysteme auflisten}
Dieser Befehl listet alle lokalen Ori-Dateisysteme auf. Hier werden Remote-Repositories nicht berücksichtigt.
\begin{lstlisting}[frame=single, caption=list]
root@ubuntu-mweinberger:/home/mweinberger# ori list

Name                            File System ID
dezsys                          0868b64e-d0ec-4c2d-9230-3ce66f301136
\end{lstlisting}

\subsubsection{replicate - Eine lokale Repository-Replik anlegen}
\label{subsubsec:replicate - Eine lokale Repository-Replik anlegen}
Der Befehl \textit{replicate} lässt Ori-Dateisysteme auf die lokale Maschine replizieren. So lässt sich ein Repository in dem Sinne 'klonen'. Langsam wird es möglich, Ori effektiv als verteiltes Dateisystem einzusetzen. Es wird nur das Dateisystem erstellt, das Verzeichnis muss händisch erstellt und gemountet werden. Folgende Befehle sind notwendig:
\begin{lstlisting}[frame=single, caption=replicate]
ori replicate root@debian:dezsys_remote

mkdir dezsys_remote
orifs dezsys_remote
\end{lstlisting}

\subsubsection{snapshot - Einen Repository-Snapshot anlegen}
\label{subsubsec:snapshot - Einen Repository-Snapshot anlegen}
In Ori dient ein Snapshot dazu, Veränderungen im Filesystem zu erkennen und diese zu speichern sowie den Commit den Remote Hosts bereitzustellen, welche das Dateisystem replizieren. Snapshots können auch zur lokalen Versionierung verwendet werden, generell vereint der Befehl \textit{commit \& push} in einem. Hier ein Beispiel, wie ein Snapshot nach Veränderungen an Dateien aussieht inkl Commit ID.
\clearpage
\begin{lstlisting}[frame=single, caption=snapshot]
root@debian:/home/mweinberger/dezsys# ori snapshot EINS
Committed 04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160

root@debian:/home/mweinberger/dezsys# echo "Hallo!" > testfile.txt

root@debian:/home/mweinberger/dezsys# ori snapshot ZWEI
Committed 8eeb2869203d968f6ae8eeb28b2714a34df5b265d46b8eeb2869203d968f6ae3
\end{lstlisting}
Die gespeicherten Zustände der Snapshots sind in Unterverzeichnissen (\textit{.snapshot}) abgelegt, weshalb ein 'Rollback' zu früheren Zuständen sehr einfach ist (herauskopieren). Ohne Veränderungen gibt der Befehl nur ein 'No changes' zurück, der restliche Vorgang wird abgebrochen.

\subsubsection{log - Eine Commit-History für das Repository}
\label{subsubsec:log - Eine Commit-History für das Repository}
Wie gewohnt sammelt der Log alle Veränderungen, die vom User ausgegangen sind. Ein Beispiel eines Logs wird hier gezeigt:
\begin{lstlisting}[frame=single, caption=log]
root@debian:/home/mweinberger/dezsys# ori log

Commit:    04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
Parents:   8df1610b6299e4bf086eae0cf473c12326ef49aeed6a3e4eed4656e3832660307
Tree:      6e9bad8eeb2869203d968f6aed02c4e79e913f6535094d8f512565bf1b8a1b58
Author:    root
Date:      Fri Apr 12 20:20:31 2016

Created snapshot 'Hallo.txt'.
\end{lstlisting}

\subsubsection{tip - Gibt den neuesten Commit aus}
\label{subsubsec:tip - Gibt den neuesten Commit aus}
Mit diesem Befehl lässt sich die aktuellste Commit ID ermitteln. Er muss jedoch in einem gemounteten Ori-Dateisystem ausgeführt werden.
\begin{lstlisting}[frame=single, caption=tip]
root@debian:/home/mweinberger/dezsys# ori tip

04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
\end{lstlisting}

\subsubsection{pull/checkout - Änderungen von einem Repository beziehen}
\label{subsubsec:pull/checkout - Änderungen von einem Repository beziehen}
Dieser Befehl ist nach Git-Ordnung eher als \textit{Fetch} zu verstehen. Alle (entfernten) Veränderungen müssen auch am lokalen Dateisystem sein. Mit \textit{pull} werden sie lediglich heruntergeladen, zurückgeliefert wird eine Commit ID. Solange bis der \textit{checkout}-Befehl mit genannter ID nicht ausgeführt wurde, sind die Files nicht im Verzeichnis vorhanden.
\begin{lstlisting}[frame=single, caption=pull]
ori pull

ori checkout 04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
\end{lstlisting}

\subsubsection{show - Repository-Informationen ausgeben}
\label{subsubsec:show - Repository-Informationen ausgeben}
\textit{show} liefert eine Menge an Informationen über das Repository. Eine mögliche Rückgabe, Struktur immer gleichbleibend:
\begin{lstlisting}[frame=single, caption=show]
root@debian:/home/mweinberger/dezsys# ori show

--- Repository ---
Root: /root/.ori/dezsys.ori
UUID: dc377ee5-79b5-406b-a844-60a8f480c1d3
Version: ORI1.1
HEAD: 04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
\end{lstlisting}

\subsubsection{status - Suche nach Veränderungen seit letztem Commit}
\label{subsubsec:status - Suche nach Veränderungen seit letztem Commit}
Wieder gibt es sehr große Parallelen zu Git: Der Befehl ist im Grunde genommen ein \textit{git status}, Ori hat jedoch eine andere Struktur. Auch dieser Befehl kann nur in einem gemounteten Ori-Dateisystem ausgeführt werden.
\begin{lstlisting}[frame=single, caption=status]
root@debian:/home/mweinberger/dezsys# ori status

A	/neues-file.txt
D	/geloeschtes-file.txt
M	/geaendertes-file.txt
\end{lstlisting}

\subsubsection{filelog - Anzeigen des Logs für ein spezifisches File}
\label{subsubsec:filelog - Anzeigen des Logs für ein spezifisches File}
\textit{ori filelog} ist in dem Sinne nur eine Erweiterung für \textit{ori log}. Auch dieser Befehl kann nur in einem gemounteten Ori-Dateisystem ausgeführt werden. Hier kann ein Filename als Parameter mitgegeben werden, welches im Repository mindestens einmal committed wurde. Nun werden alle Commits ausgegeben, bei denen das angegebene File involviert war. Als Beispiel:
\begin{lstlisting}[frame=single, caption=filelog]
root@debian:/home/mweinberger/dezsys# ori filelog dezsys.txt

Commit:    04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
Parents:   8df1610b6299e4bf086eae0cf473c12326ef49aeed6a3e4eed4656e3832660307
Tree:      6e9bad8eeb2869203d968f6aed02c4e79e913f6535094d8f512565bf1b8a1b58
Author:    root
Date:      Fri Apr 12 20:34:45 2016

Created snapshot 'neuen Text eingefuegt'.
\end{lstlisting}

\subsubsection{graft - Repository auf ein Anderes kopieren}
\label{subsubsec:graft - Repository auf ein Anderes kopieren}
Ori ermöglicht es auch, ein Repository quasi 'hard' auf das andere zu kopieren. Das Verzeichnis wird repliziert in das Verzeichnis des Ziels. Anzugeben sind lediglich Ausgangsrepository, also wovon kopiert werden soll, und das Zielrepository. Um eine aktuelle Version auf dem Zielrepository zu haben, muss nach jeder Veränderung des Ausgangsrepositorys der \textit{graft}-Befehl ausgeführt werden.
\begin{lstlisting}[frame=single, caption=graft]
ori graft dezsys dezsys-neu
\end{lstlisting}

\subsubsection{varlink - Varlink-Variablen verwalten}
\label{subsubsec:varlink - Varlink-Variablen verwalten}
Mithilfe des Befehls können die Varlink-Variablen ausgelesen, aufgelistet oder auch neu gesetzt werden. Die Ausgabe auf der Debian-VM ist leider weniger repräsentativ.
\begin{lstlisting}[frame=single, caption=varlink]
root@debian:/home/mweinberger/dezsys# ori varlink

Variable        Value                                                           
machtype        unknown                                                         
osname          unknown                                                         
domainname      (none)                                                          
hostname        debian
\end{lstlisting}

\subsubsection{merge - Mergen zweier HEADs}
\label{subsubsec:remote - Mergen zweier HEADs}
Hier gab es leider große Schwierigkeiten. Entweder wurde der Befehl falsch verwendet (obwohl wie richtig angewiesen mit Commit ID) oder er ist in der derzeitigen Version des Programms noch nicht sehr ausgereift. Es scheint so, als wäre das Dateisystem dadurch beschädigt worden, da auch andere Befehle plötzlich nicht mehr einsatzfähig sind und Fehlermeldungen werfen, und das reproduzierbar. Dieser Befehl wurde daher lieber übersprungen.
\begin{lstlisting}[frame=single, caption=merge]
root@ubuntu-mweinberger:/home/mweinberger/dezsys# ori merge 04c457f7e77dc1831eacc564bb2714a34df5b265d46b4f9e2b697564bc3ad160
merge failed with an unknown error!
\end{lstlisting}

\subsubsection{remote - Verwalten von Remoteverbindungen}
\label{subsubsec:remote - Verwalten von Remoteverbindungen}
\textit{ori remote} gibt es, um bei einer Replikation die Verbindungseinstellungen zu verwalten. Es ist ja beispielsweise gut möglich, dass sich eine IP-Adresse ändert. Umso wichtiger ist es, die Remote-Adresse ändern zu können. Es gibt drei Varianten des Befehls:
\begin{lstlisting}[frame=single, caption=remote]
ori remote

ori remote add name root@10.0.0.3:dezsys

ori remote del name
\end{lstlisting}
Der \textit{ori remote}-Befehl listet lediglich die derzeit abgespeicherten Verbindungsdaten auf. Mithilfe des zweiten Befehls lässt sich eine Remoteverbindung hinzufügen. Mit dem letzten Befehl wird der Remoteaccess wieder gelöscht.

\subsubsection{Orisync}
\label{subsubsec:Orisync}
Orisync ist ein Kommando von OriFS, der sich um die automatische Synchronisierung zwischen den Teilnehmern kümmert. \newline
\begin{lstlisting}[frame=single, caption=orisync init]
orisync init
\end{lstlisting}
Wenn Orisync initialisiert wird, wird gefragt, ob die Maschine die Erste des Clusters ist. Diese Frage wird mit 'y' beantwortet, und der Clustername wird eingegeben. In der Ausgabe steht dann nochmals der Clustername sowie und ein Cluster-Key. Wieso dieser immer den gleichen Wert 't8jhfhkm' hat, bleibt bis heute ungeklärt. Im nächsten Schritt wird wie in den vorderen Punkten beschrieben ein Dateisystem erstellt. Bei der Erstellung wird ein Verzeichnis \textit{~/.ori/dezsys.ori} erstellt, wobei 'dezsys' austauschbar ist mit dem Namen des Dateisystems. Mit dem folgenden Befehl wird das Filesystem zu orisync geadded, damit es automatisch synchronisiert. 
\begin{lstlisting}[frame=single, caption=orisync add]
orisync add ~/.ori/dezsys.ori

orisync
\end{lstlisting}
Mit der nachherigen Eingabe von \textit{orisync} wird die automatische Synchronisierung gestartet. Zum jetzigen Zeitpunkt sollten alle Files automatisch unter den Clients ausgetauscht werden. \newline
Um einem Cluster beizutreten, muss bei \textit{orisync init} 'n' eingegeben werden. Daraufhin müssen Name und Key eingegeben, und das Filesystem vom Remoteserver repliziert werden. (Wie in Anleitung oben beschrieben) Die Prozedur bei \textit{orisync add / orisync} bleibt hier ebenso gleich.

\subsection{Einsatz der Gegenspieler}
\label{subsec:Einsatz der Gegenspieler}
Im nachfolgenden Kapitel sollen Gegenspieler von OriFS, wie beispielsweise HadoopFS und GlusterFS eingesetzt werden.

\subsubsection{HadoopFS \cite{hdfs_install, hdfs_ug, hdfs_cmd}}
\label{subsubsec:HadoopFS}
''Apache Hadoop ist ein in Java entwickeltes, quelloffenes Framework, welches das Verarbeiten von großen Datenmengen, verteilt über mehrere Cluster, ermöglicht. Es besteht auch mehreren Modulen, wie Hadoop Yarn und Hadoop MapReduce, die zur Verwaltung von Ressourcen eines Clusters dienen. Das Module Hadoop Distributed File System (HDFS) bietet einen Zugriff mit einem hohen Datendurchsatz auf Applikationsdaten an. Andere Untermodule, wie beispielsweise Cassandra, HBase oder Zookeeper sind ebenfalls Bestandteil dieses Frameworks.

Hadoop wird von großen Firmen für ihre Dienste verwendet. Firmen, wie Yahoo! oder Facebook machen intensiv Gebrauch davon. Yahoo! betreibt 42 000 Nodes in seinem Hadoop Cluster (Stand: Juli 2011), während Facebook mehr, als 100 PB an Daten unter Verwendung von HadoopFS speichert. Andere Firmen, wie Amazon, eBay, LinkedIn, ... machen ebenfalls Gebrauch davon.'' \cite{comparison}

\subsubsection{Installation and Konfiguration von HDFS}
\label{subsubsec:Installation and Konfiguration von HDFS}
Zunächst müssen Java, SSH und rsync installiert werden. HDFS wurde in Java entwickelt, ein SSH Zugriff auf den HDFS Daemon wird ebenfalls benötigt.

\begin{lstlisting}[frame=single, language=bash, caption=Installieren der benötigten Softwarepakete]
apt-get install openssh-server rsync openjdk-8-jre
\end{lstlisting}

Nun kann die Installation von HDFS erfolgen.
\begin{lstlisting}[frame=single, language=bash, caption=Herunterladen und Entpacken von HDFS]
wget http://mirror.klaus-uwe.me/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz
tar xf hadoop-2.7.2.tar.gz
\end{lstlisting}

Als nächstes muss der Pfad zu Java in der Datei \textit{<hadoop-root>/etc/hadoop/hadoop-env.sh} gesetzt werden. Im Rahmen dieser Übung wird die Version 1.8 Build 77 verwendet.

\begin{lstlisting}[frame=single, language=bash, caption=Setzen des Java Pfades in <hadoop-root>/etc/hadoop/hadoop-env.sh]
export JAVA_HOME=/usr
\end{lstlisting}


\subsubsection{Ausführen eines Examples}
\label{subsubsec:Ausführen eines Examples}
Das Example wird in einem Cluster mit nur einer einzigen Node im Pseudo-Distributed Modus ausgeführt.
Hierzu wird der Cluster in der Datei textit{<hadoop-root>/etc/hadoop/core-site.xml} und textit{<hadoop-root>/etc/hadoop/hdfs-site.xml} konfiguriert.
\begin{lstlisting}[language=bash, caption=Setzen des Hosts in <hadoop-root>/etc/hadoop/core-site.xml]
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://localhost:9000</value>
	</property>
</configuration>
\end{lstlisting}

\begin{lstlisting}[language=bash, caption=Setzen der Anzahl der Replikate in <hadoop-root>/etc/hadoop/hdfs-site.xml]
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>
\end{lstlisting}

It should be able to connect with SSH to localhost without any passphrase, if this is not possible:
An dieser Stell sollte die passwortlose Anmeldung via SSH funktionieren. Sollte dies nicht der Fall sein, können folgende Befehle Abhilfe verschaffen.
\begin{lstlisting}[language=bash, caption=SSH Konfiguration]
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
\end{lstlisting}

Nun muss das Dateisystem der Node formatiert werden.
\begin{lstlisting}[language=bash, caption=Formatieren des Dateisystems]
<hadoop-root>/bin/hdfs namenode -format
\end{lstlisting}

Starten des NameNode und DataNode Daemons:
\begin{lstlisting}[language=bash, caption=Starten des NameNode und DataNode Daemons]
<hadoop-root>/sbin/start-dfs.sh
\end{lstlisting}

Nun sollte das Aufrufen des Webinterfaces unter \textit{http://localhost:50070/} möglich sein.

Als nächstes erstellen wir ein entsprechendes Verzeichnis, um den MapReduce-Job ausführen zu können.
\begin{lstlisting}[language=bash, caption=Erstellen eines Verzeichnisses in dem die Daten gespeichert werden sollen]
<hadoop-root>/bin/hdfs dfs -mkdir /userin
<hadoop-root>/bin/hdfs dfs -mkdir /userout
\end{lstlisting}

Nun werden die Daten in das HDFS kopiert.
\begin{lstlisting}[language=bash, caption=Kopieren von Files ins HDFS]
<hadoop-root>/bin/hdfs dfs -put etc/hadoop /userin
\end{lstlisting}

Ausführen eines Hadoop Examples.
\begin{lstlisting}[language=bash, caption=Ausführen eines Hadoop Examples]
<hadoop-root>/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep /userin /userout 'dfs[a-z.]+'
\end{lstlisting}

Copy the output files from the distributed filesystem to the local filesystem and examine them:
Kopieren von Daten aus dem HDFS in das lokale Dateisystem mit 
\begin{lstlisting}[language=bash, caption=Kopieren von Files aus dem HDFS]
<hadoop-root>/bin/hdfs dfs -get /userin output
cat output/*
\end{lstlisting}

Das Einsehen von im Dateisystem gespeicherten Dateien ist über ein Webinterfaces möglich.
Das Einsehen des Logs ist sowohl über die Konsole, aber auch unter \textit{http://localhost:50070/logs/} möglich.

\subsubsection{GlusterFS}
\label{subsubsec:GlusterFS}
GlusterFS ist ein von RedHat entwickeltes quelloffenes verteiltes Dateisystem, welches unter der GNU GPL und anderen Open Source Lizenzen veröffentlicht wird. Es können Dateien im Größenbereich von mehreren Petabyte gespeichert, die von mehreren Tausend Clients verwendet werden können. Es wird ein globaler Namespace verwendet, die Daten werden über storage blocks, welche über TCP/IP oder Infiband RDMA erreichbar sind, bereitgestellt.

Daten, welche in solchen Speicherblöcken abgelegt werden, können vom GlusterFS Server verwaltet und über den GlusterFS Client oder CIFS verwendet werden.

Es ist nicht möglich Dateien zwischen Server Nodes teilen zu lassen. Daten werden hier von mehreren Clients innerhalb des Dateisystems hinzugefügt, verändert und gelöscht. Im Normalfall werden Dateien als Ganzes auf jedem Server Node gespeichert. Die Verwendung von Striping (Dateien werden auf mehrere Teile auf mehrere Nodes aufgeteilt) ist ebenso möglich. Verzeichnisse werden vollständig exportiert, Daten müssen seitens des Clients restrukturiert werden. \cite{glusterabout, glusterwiki}


\subsubsection{Installation und Konfiguration von GlusterFS \cite{glusterserverinstall, glusterclientinstall}}
\label{subsubsec:Installation und Konfiguration von GlusterFS}
Zunächst muss der GlusterFS Server auf beiden Serverinstanzen installiert werden. Hier werden zwei Ubuntu 15.10 Server verwendet.
\begin{lstlisting}[language=bash, caption=Installation des GlusterFS Servers]
apt-get install glusterfs-server
\end{lstlisting}

Beide Server enthalten einen entsprechenden Eintrag in \textit{/etc/hosts}. Dieser Vorgang muss auf beiden Servern durchgeführt werden.
\begin{lstlisting}[language=bash, caption=Vorbereiten von /etc/hosts]
192.168.130.128	gluster1.example.com	gluster1
192.168.130.129	gluster2.example.com	gluster2
\end{lstlisting}

Beide Server werden als ein Teilnehmer zu dem Cluster hinzugefügt.
\begin{lstlisting}[language=bash, caption=Hinzufügen der Server zum Cluster]
gluster1> gluster peer probe gluster2
gluster2> gluster peer probe gluster1
\end{lstlisting}

Nun wird der Status der Teilnehmer überprüft.
\begin{lstlisting}[language=bash, caption=Überprüfen des Status der Teilnehmer]
gluster1> gluster peer status

Number of Peers: 1
Hostname: gluster2
Uuid: 1c8c2dfe-fb62-49a9-9e45-a749f3b3c0bf
State: Peer in Cluster (Connected)
\end{lstlisting}

In diesem Schritt wird ein Verzeichnis angelegt, welches zur Replikation der Clientdaten verwendet werden soll. Dieser Schritt muss auf beiden Servern ausgeführt werden.
\begin{lstlisting}[language=bash, caption=Erstellen eines Replikationsverzeichnisses]
mkdir -p /mnt/gluster
\end{lstlisting}

Erstellen eines Volumes mit dem Namen \textit{data} und Verbinden mit dem zuvor erstellten Verzeichnis.
\begin{lstlisting}[language=bash, caption=Erstellen des data Volumes]
gluster1> gluster volume create data replica 2 gluster1:/mnt/gluster gluster2:/mnt/gluster force
gluster1> gluster volume start data

volume start: data: success
\end{lstlisting}

Installation des GlusterFS Clients auf einem beliebigen Debian Testing Client.
\begin{lstlisting}[language=bash, caption=Installation des GlusterFS Clients]
apt-get install glusterfs-client
\end{lstlisting}

Erstellen eines Verzeichnisses, in dem die Daten später auf den Server übertragen werden sollen.
\begin{lstlisting}[language=bash, caption=Erstellen einer Verzeichnisses]
mkdir -p /mnt/gluster
\end{lstlisting}

Einbinden des zu replizierenden Volumes.
\begin{lstlisting}[language=bash, caption=Einbinden des zu replizierenden Volumes]
mount -t glusterfs 192.168.188.41:/data /mnt/gluster
\end{lstlisting}

Daraufhin erscheint folgende Fehlermeldung.
\begin{lstlisting}[language=bash, caption=Fehler der beim Einbinden des Verzeichnisses auftritt]
Mount failed. Please check the log file for more details.

[2015-03-19 16:51:04.426710] I [fuse-bridge.c:3724:fuse_init] 0-glusterfs-fuse: FUSE inited with protocol versions: glusterfs 7.13 kernel 7.22
[2015-03-19 16:51:04.426878] W [fuse-bridge.c:705:fuse_attr_cbk] 0-glusterfs-fuse: 2: LOOKUP() / => -1 (No such file or directory)
[2015-03-19 16:51:04.492092] I [fuse-bridge.c:4628:fuse_thread_proc] 0-fuse: unmounting /mnt/gluster2
[2015-03-19 16:51:04.492589] W [glusterfsd.c:1002:cleanup_and_exit] (-->/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fa6a045647d] (-->/lib/x86_64-linux-gnu/libpthread.so.0(+0x8182) [0x7fa6a0729182] (-->/usr/sbin/glusterfs(glusterfs_sigwaiter+0xd5) [0x7fa6a1212ef5]))) 0-: received signum (15), shutting down
[2015-03-19 16:51:04.492606] I [fuse-bridge.c:5260:fini] 0-fuse: Unmounting '/mnt/gluster2'.
\end{lstlisting}

Da keine Lösung für dieses konkrete Problem gefunden werden konnte, wird gluster1 als Client verwendet und ein neuer Ordner zum Testen angelegt.
\begin{lstlisting}[language=bash, caption=Erstellen eines Verzeichnisses welches repliziert wird]
mkdir -p /mnt/gluster-client
\end{lstlisting}

\subsubsection{Ausführen eines eigenen Examples}
\label{subsubsec:Ausführen eines eigenen Examples}
Einbinden des zu replizierenden Volumes.
\begin{lstlisting}[language=bash, caption=Einbinden des zu replizierenden Volumes]
mount -t glusterfs gluster1:/data /mnt/gluster-client
\end{lstlisting}
\clearpage

Nun wird der Inhalt von gluster und gluster-client auf gluster1 überprüft.
\begin{lstlisting}[language=bash, caption=Überprüfen des zu replizierenden und des replizierten Volumes]
gluster1> ls -la /mnt/gluster
total 20
drwxr-xr-x 4 root root 4096 Apr 22 03:14 .
drwxr-xr-x 4 root root 4096 Apr 22 03:27 ..
drw------- 6 root root 4096 Apr 22 03:15 .glusterfs
drwxr-xr-x 3 root root 4096 Apr 22 03:14 .trashcan

gluster1> ls -la /mnt/gluster-client/
total 12
drwxr-xr-x 4 root root 4096 Apr 22 03:14 .
drwxr-xr-x 4 root root 4096 Apr 22 03:27 ..
drwxr-xr-x 3 root root 4096 Apr 22 03:14 .trashcan
\end{lstlisting}

Abschließend wird eine Datei angelegt und wieder der Inhalt der Verzeichnisse überprüft.
\begin{lstlisting}[language=bash, caption=Überprüfen des zu replizierenden und des replizierten Volumes]
gluster1> touch /mnt/gluster-client/test.text

gluster1> ls -la /mnt/gluster-client/
total 13
drwxr-xr-x 4 root root 4096 Apr 22 03:42 .
drwxr-xr-x 4 root root 4096 Apr 22 03:27 ..
-rw-r--r-- 1 root root   10 Apr 22 03:42 test.text
drwxr-xr-x 3 root root 4096 Apr 22 03:14 .trashcan

gluster1> ls -la /mnt/gluster
total 28
drwxr-xr-x 4 root root 4096 Apr 22 03:42 .
drwxr-xr-x 4 root root 4096 Apr 22 03:27 ..
drw------- 9 root root 4096 Apr 22 03:42 .glusterfs
-rw-r--r-- 2 root root   10 Apr 22 03:42 test.text
drwxr-xr-x 3 root root 4096 Apr 22 03:14 .trashcan

gluster2> ls -la /mnt/gluster
total 28
drwxr-xr-x 4 root root 4096 Apr 22 03:42 .
drwxr-xr-x 4 root root 4096 Apr 22 03:27 ..
drw------- 9 root root 4096 Apr 22 03:42 .glusterfs
-rw-r--r-- 2 root root   10 Apr 22 03:42 test.text
drwxr-xr-x 3 root root 4096 Apr 22 03:14 .trashcan
\end{lstlisting}
\clearpage

\subsection{Gegenüberstellung}
\label{subsec:Gegenüberstellung}
\begin{table}[h]
\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Kriterium}     & \textbf{OriFS} & \textbf{HDFS} & \textbf{GlusterFS} \\ \hline \hline
		Dokumentation    &      wenig         &      gut        &          gut         \\ \hline
		Usability        &      schlecht         &	mäßig	&          schlecht         \\ \hline
		Community        &      wenig         &      aktiv        &		mäßig aktiv		\\ \hline
		Fehlertoleranz  &      gut         &      gut        &          gut         \\ \hline
		Hochverfügbarkeit &      gut         &      gut        &	mäßig	\\ \hline
		Replikation      &      gut         &      gut        &          gut         \\ \hline
		Skalierbarkeit     &      gut         &      gut        &          gut         \\ \hline \hline
		\textbf{Ranking} & 2.               &	1.	&2.\\ \hline
	\end{tabular}
\end{table}

Die Dokumentation der Befehle für OriFS ist in nur mäßigem Umfang enthalten. Die Dokumentation für HDFS und GlusterFS ist vergleichsweise sehr gut geschrieben, da für viele Anwendungsfälle auch kleine Tutorials vorhanden, die sich im Normalfall auch in der Form umsetzen lassen.

Nur ca. die Hälfte der Testfälle für OriFS funktionieren und, selbst, wenn sie funktionieren, dann sind sie stellenweise nicht unbedingt hilfreich. Die Examples für HDFS ließen sich problemlos ausführen. GlusterFS hat schlussendlich auch sehr gut funktioniert, trotz des kleinen Zwischenfalls.

OriFS ist ein neues verteiltes Dateisystem, welches aktuell noch in Entwicklung ist. Infolgedessen ist die Community wahrscheinlich klein. Manche Befehle, wie \textit{merge} und manchmal auch \textit{orisync} wurden noch nicht ausreichend getestet und können einen dauerhaften Schaden am Repository verursachen. Manche Befehle, wie \textit{pull} sollten die Daten herunterladen und anwenden, wie bei git. Stattdessen werden sie aber nur heruntergeladen, was für Verwirrung sorgen kann. Aufgrund dieser Defizite fällt das Fazit für OriFS nur mäßig aus.